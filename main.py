#!/usr/bin/env python3
import os
import sys
import argparse
import asyncio
import logging
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List

# Load environment variables from .env file
load_dotenv()

# Import the workflow
from workflow import run_exploitation_analysis
from fetch import SentryDigestFetcher
from analyze import filter_exploitation_articles, analyze_exploitation

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("exploitation-analysis.log")
    ]
)
logger = logging.getLogger(__name__)

async def main():
    """Main function to run the application"""
    logger.info("Starting SentryDigest Exploitation Report Generator")
    
    # Load configuration
    config_path = os.path.join(os.path.dirname(__file__), "config.json")
    try:
        with open(config_path, "r") as f:
            config = json.load(f)
    except Exception as e:
        logger.error(f"Error loading configuration: {e}")
        config = {
            "feed_url": "https://ricomanifesto.github.io/SentryDigest/feed.xml",
            "output_path": "index.md",
            "analysis": {
                "model": "gpt-4o",
                "temperature": 0.1
            }
        }
    
    # Create SentryDigest fetcher
    feed_url = config.get("feed_url", "https://ricomanifesto.github.io/SentryDigest/feed.xml")
    fetcher = SentryDigestFetcher(feed_url)
    
    try:
        # Fetch articles
        articles = await fetcher.fetch_articles()
        logger.info(f"Fetched {len(articles)} articles")
        
        # Enrich articles with content
        enriched_articles = await fetcher.enrich_article_content(articles)
        logger.info(f"Enriched {len(enriched_articles)} articles with content")
        
        # Filter articles for exploitation content - now passing all articles to AI
        exploitation_articles = filter_exploitation_articles(enriched_articles)
        logger.info(f"Preparing {len(exploitation_articles)} articles for AI analysis")
        
        # Analyze exploitation
        exploitation_analysis = await analyze_exploitation(exploitation_articles, config)
        logger.info("Completed exploitation analysis")
        
        # Generate report with AI output
        report = f"""# SentryDigest Exploitation Report - {exploitation_analysis.get('date', datetime.now().strftime('%Y-%m-%d'))}

{exploitation_analysis.get('exploitation_report', 'Error generating report')}

---
*Generated by SentryDigest Exploitation Report Generator*
"""
        
        # Save report to file
        output_path = config.get("output_path", "index.md")
        with open(output_path, "w") as f:
            f.write(report)
        logger.info(f"Saved report to {output_path}")
        
    except Exception as e:
        logger.error(f"Error generating report: {e}")
        
    finally:
        # Close client
        await fetcher.client.aclose()
        logger.info("Closed HTTP client")

if __name__ == "__main__":
    # Run the main function
    asyncio.run(main())
